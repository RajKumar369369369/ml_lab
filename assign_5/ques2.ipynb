{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797f0eb3-e76a-480f-b706-9704bd840a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(r\"D:\\PycharmProjects\\pythonProject\\U23AI113\\ML_lAB\\LAB_5\\archive (5)\\Iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41102999-71a4-49f7-9e55-984525a1b96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a98e8f0-fd6a-42cd-81ac-77b77892d88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array([1 if name=='Iris-setosa' else 0 for name in df['Species']]).reshape(-1,1)\n",
    "y\n",
    "#y = np.array([1 if i==name else 0 for i in df['Species']]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a82d625-3034-43ea-bbdd-946cffe4233a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array([1 if name=='Iris-setosa' else 0 for name in df['Species']]).reshape(-1,1)\n",
    "y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ab9404c-80e5-4ada-9bfb-325a5a953cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.flatten()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "282a297b-b132-4c10-a24c-5909ce89f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y[y.flatten()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d1f7542-e439-4282-b261-3f71d9168ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333333333335"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ec7ef205-827e-4468-9c3b-516a277fa41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaf6cf07-acd6-494d-a02a-5dabcbf83dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "result = np.vstack(([a]*3, b))\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a51941c-c3d9-4ae2-99b4-18b6381f4035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mak_dataset(name):\n",
    "    lis=[]\n",
    "    for i in df['Species']:\n",
    "        if i== name:\n",
    "            lis.append(1)\n",
    "        else: lis.append(0)\n",
    "    return np.array(lis).reshape(df.shape[0],-1)\n",
    "\n",
    "Iris_setosa = mak_dataset('Iris-setosa')\n",
    "Iris_setosa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b38059a-2178-4217-8836-2d46aa86fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris_versicolor=mak_dataset('Iris-versicolor')\n",
    "Iris_virginica=mak_dataset('Iris-virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c115a0-1937-4e8d-bef9-d750c1ede6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Id','Species']).values\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e14ba2-452b-49ba-bb6c-f0731c72d767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84333333, 3.054     , 3.75866667, 1.19866667])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean=X.mean(axis=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d512c2ce-5069-4f5f-9e7f-f5c777040e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82530129, 0.43214658, 1.75852918, 0.76061262])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std=X.std(axis=0)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "483af845-f27a-478a-b3e1-4c15b11a9758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
       "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],\n",
       "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673],\n",
       "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673],\n",
       "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=(X-mean)/std\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e68df5-4920-401f-a474-6824682ca162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=np.ones((X.shape[0],1))\n",
    "c.shape\n",
    "X=np.hstack([c,X])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81c1048f-6f82-4e96-a6d8-7fab01ebf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris_setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4959adff-eb41-4e12-a05a-9ce04edf7507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "        34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_idx=np.where(Iris_setosa==1)\n",
    "cls_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "355e9d95-d1bf-42d7-b322-f91964235ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(X,y,train_size,val_size,seed=113):\n",
    "    np.random.seed(seed)\n",
    "    classes = np.unique(y)\n",
    "    train_idx, val_idx = [], []\n",
    "    for c in classes:\n",
    "        cls_idx=np.where(y==c)[0]\n",
    "        np.random.shuffle(cls_idx)\n",
    "        n_total=len(cls_idx)\n",
    "        n_train=int(n_total*train_size)\n",
    "        train_idx.extend(cls_idx[:n_train])\n",
    "        val_idx.extend(cls_idx[n_train:])\n",
    "    np.random.shuffle(train_idx)\n",
    "    np.random.shuffle(val_idx)\n",
    "    return X[train_idx],y[train_idx],X[val_idx],y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a293bd2-6896-4c57-9ba5-d5bd7904a524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 5)\n"
     ]
    }
   ],
   "source": [
    "#'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'\n",
    "X_train,Iris_setosa_train,X_val,Iris_setosa_val = train_val_split(X,Iris_setosa,0.8,0.2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a50659a0-0a7c-406d-8dda-179c0c3b7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris_setosa_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71d054a6-31a3-4202-9032-5e882bc8d856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (80:20): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self,lr=0.01,epochs=1000):\n",
    "        self.lr=lr\n",
    "        self.epochs=epochs\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        n_samples,n_features = X.shape\n",
    "        self.weights=np.random.rand(n_features,1)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            y_pred=X@self.weights\n",
    "            error=y_pred-y\n",
    "            grad=(2/X.shape[0])*(X.T@error)\n",
    "            self.weights-=self.lr*grad\n",
    "      \n",
    "    def predict(self,X):\n",
    "        return X@self.weights\n",
    "\n",
    "    \n",
    "model_Iris_setosa=linear_regression(lr=0.01,epochs=100)\n",
    "model_Iris_setosa.fit(X_train,Iris_setosa_train)\n",
    "\n",
    "def to_class(pred):\n",
    "        if pred<1: return 0\n",
    "        else: return 1\n",
    "\n",
    "y_predict_val= model_Iris_setosa.predict(X_val)\n",
    "y_predict_val_class = np.array([to_class(p) for p in y_predict_val])\n",
    "\n",
    "val_acc = np.mean(y_predict_val_class.reshape(-1,1) == Iris_setosa_val)\n",
    "print(\"Validation Accuracy (80:20):\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4f63353d-fe14-4d77-9797-b86cfae478ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'linear_regression' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_Iris_versicolor=linear_regression(lr=\u001b[32m0.01\u001b[39m,epochs=\u001b[32m100\u001b[39m)\n\u001b[32m      4\u001b[39m model_Iris_setosa.fit(X_train,Iris_versicolor_train)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m y_predict_val= \u001b[43mmodel_Iris_versicolor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m y_predict_val_class = np.array([to_class(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m y_predict_val])\n\u001b[32m      9\u001b[39m val_acc = np.mean(y_predict_val_class.reshape(-\u001b[32m1\u001b[39m,\u001b[32m1\u001b[39m) == Iris_versicolor_val)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mlinear_regression.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;129m@self\u001b[39m\u001b[43m.\u001b[49m\u001b[43mweights\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'linear_regression' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "X_train,Iris_versicolor_train,X_val,Iris_versicolor_val = train_val_split(X,Iris_versicolor,0.8,0.2)\n",
    "\n",
    "model_Iris_versicolor=linear_regression(lr=0.01,epochs=100)\n",
    "model_Iris_setosa.fit(X_train,Iris_versicolor_train)\n",
    "\n",
    "y_predict_val= model_Iris_versicolor.predict(X_val)\n",
    "y_predict_val_class = np.array([to_class(p) for p in y_predict_val])\n",
    "\n",
    "val_acc = np.mean(y_predict_val_class.reshape(-1,1) == Iris_versicolor_val)\n",
    "print(\"Validation Accuracy (80:20):\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea022217-9296-450a-8b3d-13bbb8f97b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mak_bal_dataset(name):\n",
    "    y = np.array([1 if i==name else 0 for i in df['Species']]).reshape(-1,1)\n",
    "    X = df.drop(columns=['Id','Species']).values\n",
    "    X=(X-X.mean(axis=0))/X.std(axis=0)\n",
    "    c=np.ones((X.shape[0],1))\n",
    "    X=np.hstack([c,X])\n",
    "    X_pos, y_pos = X[y.flatten()==1], y[y.flatten()==1]\n",
    "    X_neg, y_neg = X[y.flatten()==0], y[y.flatten()==0]\n",
    "\n",
    "    max_count = max(len(X_pos), len(X_neg))\n",
    "\n",
    "    #balancing positives\n",
    "    reps_pos = max_count // len(X_pos)\n",
    "    rem_pos  = max_count % len(X_pos)\n",
    "    X_pos_bal = np.vstack([X_pos]*reps_pos + [X_pos[:rem_pos]])\n",
    "    y_pos_bal = np.vstack([y_pos]*reps_pos + [y_pos[:rem_pos]])\n",
    "\n",
    "    #balancing negatives\n",
    "    reps_neg = max_count // len(X_neg)\n",
    "    rem_neg  = max_count % len(X_neg)\n",
    "    X_neg_bal = np.vstack([X_neg]*reps_neg + [X_neg[:rem_neg]])\n",
    "    y_neg_bal = np.vstack([y_neg]*reps_neg + [y_neg[:rem_neg]])\n",
    "\n",
    "    #Combining bot + and -ves\n",
    "    X_bal = np.vstack([X_pos_bal, X_neg_bal])\n",
    "    y_bal = np.vstack([y_pos_bal, y_neg_bal])\n",
    "\n",
    "    return X_bal, y_bal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "00a83184-bc59-4733-b2d2-1c378cd56d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_setosa, y_setosa = mak_bal_dataset('Iris-setosa')\n",
    "X_versicolor, y_versicolor = mak_bal_dataset('Iris-versicolor')\n",
    "X_virginica, y_virginica = mak_bal_dataset('Iris-virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ba89e89-753c-4d17-8c17-4f23d5224cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 5)\n"
     ]
    }
   ],
   "source": [
    "#'Iris-setosa', 'Iris-versicolor', 'Iris-virginica'\n",
    "X_setosa_train,y_setosa_train,X_setosa_val,y_setosa_val = train_val_split(X_setosa,y_setosa,0.8,0.2)\n",
    "print(X_setosa_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eae0405b-9282-489b-86ca-692938d13c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (80:20): 0.575\n"
     ]
    }
   ],
   "source": [
    "model_setosa=linear_regression(lr=0.01,epochs=100)\n",
    "model_setosa.fit(X_setosa_train,y_setosa_train)\n",
    "\n",
    "y_predict_val= model_setosa.predict(X_setosa_val)\n",
    "y_predict_val_class = np.array([to_class(p) for p in y_predict_val])\n",
    "\n",
    "val_acc = np.mean(y_predict_val_class.reshape(-1,1) == y_setosa_val)\n",
    "print(\"Validation Accuracy (80:20):\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde94944-458d-42d2-b6e8-7b0d97cc3af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa     Validation Accuracy: 0.625\n",
      "Iris-versicolor Validation Accuracy: 0.500\n",
      "Iris-virginica  Validation Accuracy: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAJKUMAR BOKKISAM\\AppData\\Local\\Temp\\ipykernel_25004\\2300779753.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return int(pred >= 1)   # threshold chosen to match original code\n",
      "C:\\Users\\RAJKUMAR BOKKISAM\\AppData\\Local\\Temp\\ipykernel_25004\\2300779753.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return int(pred >= 1)   # threshold chosen to match original code\n",
      "C:\\Users\\RAJKUMAR BOKKISAM\\AppData\\Local\\Temp\\ipykernel_25004\\2300779753.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return int(pred >= 1)   # threshold chosen to match original code\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_iris(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load the Iris CSV file.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "# ---------------------- 2. Utilities ---------------------- #\n",
    "def make_dataset(df: pd.DataFrame, species_name: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a binary target array: 1 for species_name, 0 for others.\n",
    "    Shape -> (n_samples, 1)\n",
    "    \"\"\"\n",
    "    return np.array([1 if s == species_name else 0 for s in df['Species']]\n",
    "                   ).reshape(-1, 1)\n",
    "\n",
    "def train_val_split(X: np.ndarray, y: np.ndarray,\n",
    "                    train_size: float = 0.8,\n",
    "                    seed: int = 113):\n",
    "    \"\"\"\n",
    "    Stratified train/validation split.\n",
    "    Returns: X_train, y_train, X_val, y_val\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    classes = np.unique(y)\n",
    "    train_idx, val_idx = [], []\n",
    "    for c in classes:\n",
    "        idx = np.where(y == c)[0]\n",
    "        np.random.shuffle(idx)\n",
    "        n_train = int(len(idx) * train_size)\n",
    "        train_idx.extend(idx[:n_train])\n",
    "        val_idx.extend(idx[n_train:])\n",
    "    np.random.shuffle(train_idx)\n",
    "    np.random.shuffle(val_idx)\n",
    "    return X[train_idx], y[train_idx], X[val_idx], y[val_idx]\n",
    "\n",
    "def to_class(pred: float) -> int:\n",
    "    \"\"\"Convert regression output to class (0 or 1).\"\"\"\n",
    "    return int(pred >= 1)   # threshold chosen to match original code\n",
    "\n",
    "# ---------------------- 3. Simple Linear Regression ---------------------- #\n",
    "class LinearRegression:\n",
    "    def __init__(self, lr: float = 0.01, epochs: int = 1000):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.rand(n_features, 1)\n",
    "        for _ in range(self.epochs):\n",
    "            y_pred = X @ self.weights\n",
    "            error = y_pred - y\n",
    "            grad = (2 / n_samples) * (X.T @ error)\n",
    "            self.weights -= self.lr * grad\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return X @ self.weights\n",
    "\n",
    "# ---------------------- 4. Balanced Dataset ---------------------- #\n",
    "def make_balanced_dataset(df: pd.DataFrame, species_name: str):\n",
    "    \"\"\"\n",
    "    Make a balanced (1 vs rest) dataset for the given species.\n",
    "    Adds a bias column and standardises features.\n",
    "    Returns: X_bal, y_bal\n",
    "    \"\"\"\n",
    "    y = make_dataset(df, species_name)\n",
    "    X = df.drop(columns=['Id', 'Species']).values\n",
    "    # Standardise features\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Add bias term (column of ones)\n",
    "    X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "    X_pos, y_pos = X[y.flatten() == 1], y[y.flatten() == 1]\n",
    "    X_neg, y_neg = X[y.flatten() == 0], y[y.flatten() == 0]\n",
    "\n",
    "    max_count = max(len(X_pos), len(X_neg))\n",
    "\n",
    "    def oversample(X_cls, y_cls):\n",
    "        reps = max_count // len(X_cls)\n",
    "        rem = max_count % len(X_cls)\n",
    "        return (np.vstack([X_cls] * reps + [X_cls[:rem]]),\n",
    "                np.vstack([y_cls] * reps + [y_cls[:rem]]))\n",
    "\n",
    "    X_pos_bal, y_pos_bal = oversample(X_pos, y_pos)\n",
    "    X_neg_bal, y_neg_bal = oversample(X_neg, y_neg)\n",
    "\n",
    "    X_bal = np.vstack([X_pos_bal, X_neg_bal])\n",
    "    y_bal = np.vstack([y_pos_bal, y_neg_bal])\n",
    "    return X_bal, y_bal\n",
    "\n",
    "# ---------------------- 5. Training + Evaluation ---------------------- #\n",
    "def run_one_vs_rest(df: pd.DataFrame, species_name: str):\n",
    "    \"\"\"Train & validate a simple regressor for one-vs-rest classification.\"\"\"\n",
    "    X_bal, y_bal = make_balanced_dataset(df, species_name)\n",
    "    X_train, y_train, X_val, y_val = train_val_split(X_bal, y_bal, 0.8)\n",
    "\n",
    "    model = LinearRegression(lr=0.01, epochs=100)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_pred_class = np.array([to_class(p) for p in y_pred_val])\n",
    "    val_acc = np.mean(y_pred_class.reshape(-1, 1) == y_val)\n",
    "\n",
    "    print(f\"{species_name:15s} Validation Accuracy: {val_acc:.3f}\")\n",
    "\n",
    "# ---------------------- 6. Main ---------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    path = r\"D:\\PycharmProjects\\pythonProject\\U23AI113\\ML_lAB\\LAB_5\\archive (5)\\Iris.csv\"\n",
    "    df = load_iris(path)\n",
    "\n",
    "    for sp in ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']:\n",
    "        run_one_vs_rest(df, sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f3a510-867d-429b-b855-960ba18f3db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True species : Iris-setosa\n",
      "Predicted    : Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# --- After training the three binary models ---\n",
    "species = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "# Train and keep all models\n",
    "models = {}\n",
    "for sp in species:\n",
    "    X_bal, y_bal = make_balanced_dataset(df, sp)\n",
    "    X_train, y_train, X_val, y_val = train_val_split(X_bal, y_bal, 0.8)\n",
    "    model = LinearRegression(lr=0.01, epochs=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    models[sp] = model\n",
    "\n",
    "# -------- Predict the correct 3-class label -------- #\n",
    "def predict_species(x_single: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    x_single : shape (n_features_without_bias,)\n",
    "    Returns predicted species name.\n",
    "    \"\"\"\n",
    "    # Standardise same way as training: mean/std from full df\n",
    "    X_all = df.drop(columns=['Id', 'Species']).values\n",
    "    mean, std = X_all.mean(axis=0), X_all.std(axis=0)\n",
    "    x_std = (x_single - mean) / std\n",
    "    x_with_bias = np.hstack([1, x_std]).reshape(1, -1)\n",
    "\n",
    "    # get scores from each model\n",
    "    scores = {sp: models[sp].predict(x_with_bias)[0, 0] for sp in species}\n",
    "\n",
    "    # choose species with max score\n",
    "    return max(scores, key=scores.get)\n",
    "\n",
    "# Example: predict first row\n",
    "sample = df.drop(columns=['Id', 'Species']).values[0]\n",
    "print(\"True species :\", df['Species'].iloc[0])\n",
    "print(\"Predicted    :\", predict_species(sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21103ecc-2da9-48b9-a079-d0049bb643d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
